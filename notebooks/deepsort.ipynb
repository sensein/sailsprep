{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip3 install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-13T10:20:49.587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def draw_pose(img, keypoints, track_id=None):\n",
    "    \"\"\"Draw pose keypoints and connections with optional track ID\"\"\"\n",
    "    connections = [(0,1), (0,2), (1,3), (2,4), (5,6), (5,7), (7,9), \n",
    "                   (6,8), (8,10), (5,11), (6,12), (11,12), (11,13), \n",
    "                   (13,15), (12,14), (14,16)]\n",
    "    \n",
    "    # Draw keypoints\n",
    "    for x, y, conf in keypoints:\n",
    "        if conf > 0.5:\n",
    "            cv2.circle(img, (int(x), int(y)), 4, (0, 255, 0), -1)\n",
    "    \n",
    "    # Draw connections\n",
    "    for start, end in connections:\n",
    "        if (keypoints[start][2] > 0.5 and keypoints[end][2] > 0.5):\n",
    "            pt1 = (int(keypoints[start][0]), int(keypoints[start][1]))\n",
    "            pt2 = (int(keypoints[end][0]), int(keypoints[end][1]))\n",
    "            cv2.line(img, pt1, pt2, (255, 0, 0), 2)\n",
    "    \n",
    "    # Draw track ID \n",
    "    if track_id is not None and keypoints[0][2] > 0.5:\n",
    "        head_x, head_y = int(keypoints[0][0]), int(keypoints[0][1])\n",
    "        cv2.putText(img, f'ID:{track_id}', (head_x, head_y-15), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "video_path = \"/kaggle/input/360p-video/you_video360p/SSYouTube.online_3 Years - Talks well enough for strangers to understand most of the time_360p.mp4\"\n",
    "output_folder = \"/kaggle/working/\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "output_path = os.path.join(output_folder, f\"deepsort_{os.path.basename(video_path)}\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "model = YOLO('yolov8n-pose.pt').to(device)\n",
    "deepsort_tracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0) # embedder=''\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            confs = result.boxes.conf.cpu().numpy()\n",
    "            \n",
    "            for i, (box, conf) in enumerate(zip(boxes, confs)):\n",
    "                if conf > 0.5: \n",
    "                    x1, y1, x2, y2 = box\n",
    "                    detections.append(([x1, y1, x2-x1, y2-y1], conf, None))\n",
    "    \n",
    "    tracks = deepsort_tracker.update_tracks(detections, frame=frame)\n",
    "    active_tracks = []\n",
    "    for track in tracks:\n",
    "        if track.is_confirmed():\n",
    "            active_tracks.append({\n",
    "                'id': track.track_id,\n",
    "                'bbox': track.to_ltrb()\n",
    "            })\n",
    "    \n",
    "    for result in results:\n",
    "        if result.keypoints is not None:\n",
    "            keypoints = result.keypoints.xy.cpu().numpy()\n",
    "            confidences = result.keypoints.conf.cpu().numpy()\n",
    "            \n",
    "            for i, kpts in enumerate(keypoints):\n",
    "                pose_data = [[kpts[j][0], kpts[j][1], confidences[i][j]] \n",
    "                           for j in range(len(kpts))]\n",
    "\n",
    "                track_id = None\n",
    "                pose_center = (kpts[5][0] + kpts[6][0])/2, (kpts[5][1] + kpts[6][1])/2  \n",
    "                \n",
    "                for track in active_tracks:\n",
    "                    x1, y1, x2, y2 = track['bbox']\n",
    "                    if (x1 <= pose_center[0] <= x2 and y1 <= pose_center[1] <= y2):\n",
    "                        track_id = track['id']\n",
    "                        break\n",
    "                \n",
    "                draw_pose(frame, pose_data, track_id)\n",
    "    \n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Saved {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8090277,
     "sourceId": 12796183,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
