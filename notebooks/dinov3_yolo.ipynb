{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2912ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# yolo for pose estiamtion dinov3 for appearance feature extraction for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782ac06",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e8ed3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0041f38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-feature-extraction\", model=\"facebook/dinov3-vith16plus-pretrain-lvd1689m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e139d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581298e",
   "metadata": {},
   "source": [
    "# dinov3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98d03d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "tracks = {}           # Store all tracks: {track_id: track_info}\n",
    "next_id = 1          # Next available track ID\n",
    "frame_count = 0      # Current frame number\n",
    "appearance_features = {}  # Store appearance features: {track_id: features}\n",
    "\n",
    "\n",
    "APPEARANCE_THRESHOLD = 0.4         # Minimum appearance similarity (relaxed)\n",
    "FEATURE_UPDATE_ALPHA = 0.9         # Weight for existing features (more stable)\n",
    "\n",
    "\n",
    "MAX_MISSING_FRAMES = 30    # Remove track after this many frames\n",
    "MIN_CONFIDENCE = 0.5       # Minimum detection confidence\n",
    "\n",
    "# Colors for visualization\n",
    "COLORS = [\n",
    "    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "    (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 128, 0)\n",
    "]\n",
    "\n",
    "# COCO pose skeleton for drawing\n",
    "SKELETON = [\n",
    "    [16, 14], [14, 12], [17, 15], [15, 13], [12, 13],\n",
    "    [6, 12], [7, 13], [6, 7], [6, 8], [7, 9],\n",
    "    [8, 10], [9, 11], [2, 3], [1, 2], [1, 3],\n",
    "    [2, 4], [3, 5], [4, 6], [5, 7]\n",
    "]\n",
    "\n",
    "def load_dinov3_model():\n",
    "    \"\"\"Load DINOv3 model using transformers pipeline\"\"\"\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    # pipeline\n",
    "    dinov3_pipeline = pipeline(\n",
    "        \"image-feature-extraction\",\n",
    "        model=\"facebook/dinov3-vith16plus-pretrain-lvd1689m\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return dinov3_pipeline\n",
    "\n",
    "def extract_batch_features(image, detections, dinov3_pipeline):\n",
    "    \"\"\"Extract appearance features for a batch of detections\"\"\"\n",
    "    crops = []\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    for bbox in detections:\n",
    "        x1, y1, x2, y2 = map(int, bbox[:4])\n",
    "        x1 = max(0, min(x1, w-1))\n",
    "        y1 = max(0, min(y1, h-1))\n",
    "        x2 = max(x1+1, min(x2, w))\n",
    "        y2 = max(y1+1, min(y2, h))\n",
    "\n",
    "        crop = image[y1:y2, x1:x2]\n",
    "        crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(crop_rgb).resize((224, 224))\n",
    "        crops.append(pil_image)\n",
    "\n",
    "    features_list = dinov3_pipeline(crops)\n",
    "\n",
    "    processed_features = []\n",
    "    for f in features_list:\n",
    "        f = np.array(f).flatten()\n",
    "        norm = np.linalg.norm(f)\n",
    "        if norm > 0:\n",
    "            f = f / norm\n",
    "        processed_features.append(f)\n",
    "\n",
    "    return processed_features\n",
    "\n",
    "def calculate_appearance_similarity(features1, features2):\n",
    "    \"\"\"Calculate cosine similarity between appearance features\"\"\"\n",
    "    dot_product = np.dot(features1, features2)\n",
    "    norm1 = np.linalg.norm(features1)\n",
    "    norm2 = np.linalg.norm(features2)\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return max(0, similarity)\n",
    "\n",
    "def filter_detections(detections, keypoints_list):\n",
    "    \"\"\"Keep only good quality detections\"\"\"\n",
    "    if not detections:\n",
    "        return [], []\n",
    "\n",
    "    filtered_detections = []\n",
    "    filtered_keypoints = []\n",
    "\n",
    "    for i, detection in enumerate(detections):\n",
    "        x1, y1, x2, y2, conf = detection\n",
    "\n",
    "        # confidence and box size\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        area = width * height\n",
    "        aspect_ratio = width / height if height > 0 else 0\n",
    "\n",
    "        # Filter criteria\n",
    "        if (conf > MIN_CONFIDENCE and\n",
    "            area > 2000 and\n",
    "            0.2 < aspect_ratio < 5.0 and\n",
    "            width > 50 and height > 100):\n",
    "\n",
    "            filtered_detections.append(detection)\n",
    "            if i < len(keypoints_list):\n",
    "                filtered_keypoints.append(keypoints_list[i])\n",
    "            else:\n",
    "                filtered_keypoints.append(None)\n",
    "\n",
    "    return filtered_detections, filtered_keypoints\n",
    "\n",
    "def create_new_track(detection, keypoints, features):\n",
    "    \"\"\"Create a new track\"\"\"\n",
    "    global next_id, frame_count, tracks, appearance_features\n",
    "\n",
    "    track_id = next_id\n",
    "    next_id += 1\n",
    "\n",
    "    tracks[track_id] = {\n",
    "        'bbox': detection,\n",
    "        'keypoints': keypoints,\n",
    "        'missing_frames': 0,\n",
    "        'last_seen': frame_count,\n",
    "        'created_at': frame_count,\n",
    "        'match_type': 'new'\n",
    "    }\n",
    "\n",
    "    # appearance features storing\n",
    "    appearance_features[track_id] = features\n",
    "\n",
    "    return track_id\n",
    "\n",
    "def update_track(track_id, detection, keypoints, new_features, similarity):\n",
    "    \"\"\"Update existing track\"\"\"\n",
    "    global tracks, appearance_features, frame_count\n",
    "\n",
    "    tracks[track_id]['bbox'] = detection\n",
    "    tracks[track_id]['keypoints'] = keypoints\n",
    "    tracks[track_id]['missing_frames'] = 0\n",
    "    tracks[track_id]['last_seen'] = frame_count\n",
    "    tracks[track_id]['match_type'] = 'appearance'\n",
    "    tracks[track_id]['last_similarity'] = similarity\n",
    "\n",
    "    # Update appearance features with moving average\n",
    "    old_features = appearance_features[track_id]\n",
    "    appearance_features[track_id] = FEATURE_UPDATE_ALPHA * old_features + (1 - FEATURE_UPDATE_ALPHA) * new_features\n",
    "    # Normalize\n",
    "    norm = np.linalg.norm(appearance_features[track_id])\n",
    "    if norm > 0:\n",
    "        appearance_features[track_id] /= norm\n",
    "\n",
    "def remove_old_tracks():\n",
    "    \"\"\"Remove tracks that are too old\"\"\"\n",
    "    global tracks, appearance_features\n",
    "\n",
    "    tracks_to_remove = []\n",
    "    for track_id, track_info in tracks.items():\n",
    "        if track_info['missing_frames'] >= MAX_MISSING_FRAMES:\n",
    "            tracks_to_remove.append(track_id)\n",
    "\n",
    "    for track_id in tracks_to_remove:\n",
    "        del tracks[track_id]\n",
    "        if track_id in appearance_features:\n",
    "            del appearance_features[track_id]\n",
    "\n",
    "def pure_appearance_matching(detections, keypoints_list, detection_features):\n",
    "    \"\"\"\n",
    "    Pure appearance-only matching using DINOv3 features\n",
    "    Returns: list of (detection_idx, track_id, similarity) tuples\n",
    "    \"\"\"\n",
    "    global tracks, frame_count\n",
    "\n",
    "    # Get active tracks\n",
    "    active_track_ids = []\n",
    "    for track_id, track_info in tracks.items():\n",
    "        if track_info['missing_frames'] < MAX_MISSING_FRAMES:\n",
    "            active_track_ids.append(track_id)\n",
    "\n",
    "    if not active_track_ids:\n",
    "        return []  # No tracks to match\n",
    "\n",
    "    print(f\"  Pure appearance matching: {len(detections)} detections vs {len(active_track_ids)} tracks\")\n",
    "\n",
    "    matches = []\n",
    "    used_tracks = set()\n",
    "\n",
    "    # For each detection, find the best matching track based\n",
    "    for i, detection in enumerate(detections):\n",
    "        det_features = detection_features[i]\n",
    "        best_track_id = None\n",
    "        best_similarity = 0.0\n",
    "\n",
    "        # Check appearance similarity with all available tracks\n",
    "        for track_id in active_track_ids:\n",
    "            if track_id in used_tracks:\n",
    "                continue  # Track already matched\n",
    "\n",
    "            track_features = appearance_features[track_id]\n",
    "\n",
    "            # Calculate ONLY appearance similarity\n",
    "            similarity = calculate_appearance_similarity(det_features, track_features)\n",
    "\n",
    "            # Check if this is the best match so far\n",
    "            if similarity >= APPEARANCE_THRESHOLD and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_track_id = track_id\n",
    "\n",
    "        # If we found a good match, add it\n",
    "        if best_track_id is not None:\n",
    "            matches.append((i, best_track_id, best_similarity))\n",
    "            used_tracks.add(best_track_id)\n",
    "            print(f\"    Match: detection {i} -> track {best_track_id} (similarity: {best_similarity:.3f})\")\n",
    "\n",
    "    print(f\"  Found {len(matches)} pure appearance matches\")\n",
    "    return matches\n",
    "\n",
    "def update_tracks(detections, keypoints_list, image, dinov3_pipeline):\n",
    "    \"\"\"Main tracking function\"\"\"\n",
    "    global tracks, frame_count\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Filter detections\n",
    "    detections, keypoints_list = filter_detections(detections, keypoints_list)\n",
    "\n",
    "    if not detections:\n",
    "        # No detections - increment missing frames for all tracks\n",
    "        for track_id in tracks:\n",
    "            tracks[track_id]['missing_frames'] += 1\n",
    "        remove_old_tracks()\n",
    "        return\n",
    "\n",
    "    # Extract appearance features for all detections\n",
    "    print(f\"Extracting DINOv3 features for {len(detections)} detections...\")\n",
    "    detection_features = extract_batch_features(image, detections, dinov3_pipeline)\n",
    "\n",
    "    # appearance-based matching\n",
    "    matches = pure_appearance_matching(detections, keypoints_list, detection_features)\n",
    "\n",
    "    # Update matched tracks\n",
    "    matched_detection_indices = set()\n",
    "    matched_track_ids = set()\n",
    "\n",
    "    for detection_idx, track_id, similarity in matches:\n",
    "        update_track(track_id, detections[detection_idx], keypoints_list[detection_idx],\n",
    "                    detection_features[detection_idx], similarity)\n",
    "        matched_detection_indices.add(detection_idx)\n",
    "        matched_track_ids.add(track_id)\n",
    "\n",
    "    # Create new tracks for unmatched detections\n",
    "    new_tracks_count = 0\n",
    "    for i, detection in enumerate(detections):\n",
    "        if i not in matched_detection_indices:\n",
    "            create_new_track(detection, keypoints_list[i], detection_features[i])\n",
    "            new_tracks_count += 1\n",
    "\n",
    "    # Increment missing frames for unmatched tracks\n",
    "    for track_id, track_info in tracks.items():\n",
    "        if track_id not in matched_track_ids and track_info['missing_frames'] < MAX_MISSING_FRAMES:\n",
    "            tracks[track_id]['missing_frames'] += 1\n",
    "\n",
    "    remove_old_tracks()\n",
    "\n",
    "    # matching summary\n",
    "    print(f\"  Matching summary: {len(matches)} appearance matches, {new_tracks_count} new tracks\")\n",
    "\n",
    "def draw_pose(img, keypoints, color):\n",
    "    \"\"\"Draw pose keypoints and skeleton\"\"\"\n",
    "    if keypoints is None:\n",
    "        return img\n",
    "\n",
    "    # Draw keypoints\n",
    "    for i, (x, y, conf) in enumerate(keypoints):\n",
    "        if conf > 0.3:\n",
    "            cv2.circle(img, (int(x), int(y)), 4, color, -1)\n",
    "\n",
    "    # Draw skeleton\n",
    "    for connection in SKELETON:\n",
    "        pt1_idx, pt2_idx = connection[0] - 1, connection[1] - 1\n",
    "\n",
    "        if (pt1_idx < len(keypoints) and pt2_idx < len(keypoints) and\n",
    "            keypoints[pt1_idx][2] > 0.3 and keypoints[pt2_idx][2] > 0.3):\n",
    "\n",
    "            pt1 = (int(keypoints[pt1_idx][0]), int(keypoints[pt1_idx][1]))\n",
    "            pt2 = (int(keypoints[pt2_idx][0]), int(keypoints[pt2_idx][1]))\n",
    "            cv2.line(img, pt1, pt2, color, 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def draw_tracks(img, tracks):\n",
    "    \"\"\"Draw all active tracks with similarity scores\"\"\"\n",
    "    active_tracks = {tid: info for tid, info in tracks.items()\n",
    "                    if info['missing_frames'] <= 3}\n",
    "\n",
    "    for track_id, track_info in active_tracks.items():\n",
    "\n",
    "        color = COLORS[track_id % len(COLORS)]\n",
    "\n",
    "        # Draw bbox\n",
    "        bbox = track_info['bbox']\n",
    "        x1, y1, x2, y2 = map(int, bbox[:4])\n",
    "\n",
    "        # Different thickness for new vs matched tracks\n",
    "        thickness = 2 if track_info.get('match_type') == 'appearance' else 3\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "        # Draw track ID with similarity score if available\n",
    "        label = f'ID:{track_id}'\n",
    "        if 'last_similarity' in track_info:\n",
    "            label += f' ({track_info[\"last_similarity\"]:.2f})'\n",
    "        elif track_info.get('match_type') == 'new':\n",
    "            label += ' (NEW)'\n",
    "\n",
    "        cv2.putText(img, label, (x1, y1-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # pose\n",
    "        img = draw_pose(img, track_info['keypoints'], color)\n",
    "\n",
    "    return img\n",
    "\n",
    "def process_video(video_path, output_path):\n",
    "    \"\"\"Process a single video\"\"\"\n",
    "    print(f\"Processing: {video_path}\")\n",
    "\n",
    "    global tracks, next_id, frame_count, appearance_features\n",
    "    tracks = {}\n",
    "    next_id = 1\n",
    "    frame_count = 0\n",
    "    appearance_features = {}\n",
    "\n",
    "    yolo_model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "    dinov3_pipeline = load_dinov3_model()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # YOLO detection\n",
    "        results = yolo_model(frame, verbose=False)\n",
    "\n",
    "        # Extract person detections and poses\n",
    "        detections = []\n",
    "        keypoints_list = []\n",
    "\n",
    "        if results[0].boxes is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            scores = results[0].boxes.conf.cpu().numpy()\n",
    "            classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "            # Filter for person class (class 0)\n",
    "            person_indices = classes == 0\n",
    "            boxes = boxes[person_indices]\n",
    "            scores = scores[person_indices]\n",
    "\n",
    "            # Get keypoints if available\n",
    "            if results[0].keypoints is not None:\n",
    "                keypoints = results[0].keypoints.xy.cpu().numpy()[person_indices]\n",
    "                keypoints_conf = results[0].keypoints.conf.cpu().numpy()[person_indices]\n",
    "\n",
    "                for i in range(len(boxes)):\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    conf = scores[i]\n",
    "                    detections.append([x1, y1, x2, y2, conf])\n",
    "\n",
    "                    # Combine keypoint coordinates with confidence\n",
    "                    kpts = []\n",
    "                    for j in range(len(keypoints[i])):\n",
    "                        x, y = keypoints[i][j]\n",
    "                        c = keypoints_conf[i][j]\n",
    "                        kpts.append([x, y, c])\n",
    "                    keypoints_list.append(kpts)\n",
    "            else:\n",
    "                # No keypoints available\n",
    "                for i in range(len(boxes)):\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    conf = scores[i]\n",
    "                    detections.append([x1, y1, x2, y2, conf])\n",
    "                    keypoints_list.append(None)\n",
    "\n",
    "        # Update tracking\n",
    "        update_tracks(detections, keypoints_list, frame, dinov3_pipeline)\n",
    "\n",
    "        # results\n",
    "        output_frame = draw_tracks(frame.copy(), tracks)\n",
    "\n",
    "        # frame info\n",
    "        active_count = len([t for t in tracks.values() if t['missing_frames'] <= 3])\n",
    "        matched_count = len([t for t in tracks.values() if t.get('match_type') == 'appearance'])\n",
    "        new_count = len([t for t in tracks.values() if t.get('match_type') == 'new'])\n",
    "\n",
    "        info_text = f\"Frame: {frame_count}/{total_frames} | Active: {active_count} | Matched: {matched_count} | New: {new_count}\"\n",
    "        cv2.putText(output_frame, info_text, (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        writer.write(output_frame)\n",
    "\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    print(f\"Video saved to: {output_path}\")\n",
    "    print(f\"Total unique people tracked: {next_id - 1}\")\n",
    "\n",
    "    tracking_data = {\n",
    "        'video_file': os.path.basename(video_path),\n",
    "        'tracks': tracks,\n",
    "        'appearance_features': appearance_features,\n",
    "        'total_frames': frame_count,\n",
    "        'fps': fps,\n",
    "        'parameters': {\n",
    "            'appearance_threshold': APPEARANCE_THRESHOLD,\n",
    "            'feature_update_alpha': FEATURE_UPDATE_ALPHA\n",
    "        }\n",
    "    }\n",
    "\n",
    "    data_file = output_path.replace('.mp4', '_pure_appearance_tracking_data.pkl')\n",
    "    with open(data_file, 'wb') as f:\n",
    "        pickle.dump(tracking_data, f)\n",
    "    print(f\"Tracking data saved to: {data_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process all videos\"\"\"\n",
    "\n",
    "    input_folder = '/kaggle/input/360p-video/you_video360p'\n",
    "    output_folder = '/kaggle/working/pure_appearance_tracking_output'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    video_files = []\n",
    "\n",
    "    if os.path.exists(input_folder):\n",
    "        for file in os.listdir(input_folder):\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                video_files.append(file)\n",
    "    else:\n",
    "        print(f\"Input folder not found: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(video_files)} video(s) to process\")\n",
    "    print(f\"Using PURE appearance matching ONLY (threshold ≥{APPEARANCE_THRESHOLD})\")\n",
    "\n",
    "    for video_file in video_files:\n",
    "        print(f\"\\n=== Processing: {video_file} ===\")\n",
    "\n",
    "        video_path = os.path.join(input_folder, video_file)\n",
    "        output_path = os.path.join(output_folder,\n",
    "                                  video_file.replace('.mp4', 'appearance_tracked.mp4'))\n",
    "\n",
    "        try:\n",
    "            process_video(video_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    print(\"\\nAll videos processed \")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
