{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-10T04:08:02.997012Z",
     "iopub.status.idle": "2025-09-10T04:08:02.997349Z",
     "shell.execute_reply": "2025-09-10T04:08:02.997193Z",
     "shell.execute_reply.started": "2025-09-10T04:08:02.997177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install openmim\n",
    "!pip install git+https://github.com/jin-s13/xtcocoapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-10T04:08:02.997899Z",
     "iopub.status.idle": "2025-09-10T04:08:02.998223Z",
     "shell.execute_reply": "2025-09-10T04:08:02.998064Z",
     "shell.execute_reply.started": "2025-09-10T04:08:02.998049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install --trusted-host download.openmmlab.com -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html mmcv==2.0.1\n",
    "!mim install mmengine\n",
    "!mim install mmdet==3.2.0\n",
    "!git clone https://github.com/open-mmlab/mmpose.git\n",
    "%cd mmpose\n",
    "!pip install -e .\n",
    "!pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-10T04:08:03.001755Z",
     "iopub.status.idle": "2025-09-10T04:08:03.002077Z",
     "shell.execute_reply": "2025-09-10T04:08:03.001931Z",
     "shell.execute_reply.started": "2025-09-10T04:08:03.001916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd mmpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-10T04:08:03.003429Z",
     "iopub.status.idle": "2025-09-10T04:08:03.003776Z",
     "shell.execute_reply": "2025-09-10T04:08:03.003608Z",
     "shell.execute_reply.started": "2025-09-10T04:08:03.003593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import imread\n",
    "import mmengine\n",
    "from mmengine.registry import init_default_scope\n",
    "import numpy as np\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.structures import merge_data_samples\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "import cv2\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "detector = None\n",
    "pose_estimator = None\n",
    "visualizer = None\n",
    "\n",
    "\n",
    "BODY_KEYPOINTS = list(range(17))\n",
    "FACE_KEYPOINTS = list(range(17, 17 + 68))\n",
    "LEFT_HAND_KEYPOINTS = list(range(95, 95 + 21))\n",
    "RIGHT_HAND_KEYPOINTS = list(range(116, 116 + 21))\n",
    "LEFT_FOOT_KEYPOINTS = list(range(137, 140)) if 137 < 133 else []\n",
    "RIGHT_FOOT_KEYPOINTS = list(range(140, 143)) if 140 < 133 else []\n",
    "\n",
    "# 3-part body definitions\n",
    "FACE_POINTS = [0] + FACE_KEYPOINTS  # nose + all face keypoints\n",
    "\n",
    "UPPER_BODY_POINTS = [5, 6, 7, 8, 9, 10, 11, 12]  # shoulders + arms + hips (NO FACE/NECK/EYES)\n",
    "\n",
    "LOWER_BODY_POINTS = [11, 12, 13, 14, 15, 16] + LEFT_FOOT_KEYPOINTS + RIGHT_FOOT_KEYPOINTS  # hips, legs + feet\n",
    "\n",
    "# Colors for 3 body parts (BGR format for OpenCV)\n",
    "FACE_COLOR = [0, 0, 255]      # Red\n",
    "UPPER_BODY_COLOR = [0, 255, 0] # Green  \n",
    "LOWER_BODY_COLOR = [255, 0, 0] # Blue\n",
    "\n",
    "\n",
    "\n",
    "# Model initialization\n",
    "det_config = 'projects/rtmpose/rtmdet/person/rtmdet_m_640-8xb32_coco-person.py'\n",
    "det_checkpoint = 'https://download.openmmlab.com/mmpose/v1/projects/rtmpose/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth'\n",
    "pose_config = 'configs/wholebody_2d_keypoint/topdown_heatmap/coco-wholebody/td-hm_hrnet-w48_dark-8xb32-210e_coco-wholebody-384x288.py'\n",
    "pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth'\n",
    "\n",
    "detector = init_detector(det_config, det_checkpoint, device='cuda:0')\n",
    "cfg_options = dict(model=dict(test_cfg=dict(output_heatmaps=True)))\n",
    "pose_estimator = init_pose_estimator(pose_config, pose_checkpoint, device='cuda:0', cfg_options=cfg_options)\n",
    "pose_estimator.cfg.visualizer.radius = 2\n",
    "pose_estimator.cfg.visualizer.line_width = 1\n",
    "visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)\n",
    "visualizer.set_dataset_meta(pose_estimator.dataset_meta)\n",
    "\n",
    "\n",
    "img_path = '/kaggle/input/full-human-img/mother-daughter-sitting-back-to-back-6603114.webp'  \n",
    "output_dir = '/kaggle/working/outputs'\n",
    "\n",
    "img = mmcv.imread(img_path, channel_order='rgb')\n",
    "\n",
    "scope = detector.cfg.get('default_scope', 'mmdet')\n",
    "if scope is not None:\n",
    "    init_default_scope(scope)\n",
    "\n",
    "detect_result = inference_detector(detector, img_path)\n",
    "pred_instance = detect_result.pred_instances.numpy()\n",
    "\n",
    "person_mask = pred_instance.labels == 0\n",
    "score_mask = pred_instance.scores > 0.3\n",
    "valid_detections = person_mask & score_mask\n",
    "\n",
    "if not np.any(valid_detections):\n",
    "    print(\"No people detected!\")\n",
    "    exit()\n",
    "\n",
    "bboxes = np.concatenate((pred_instance.bboxes[valid_detections], \n",
    "                       pred_instance.scores[valid_detections][:, None]), axis=1)\n",
    "bboxes = bboxes[nms(bboxes, 0.3)]\n",
    "areas = (bboxes[:, 2] - bboxes[:, 0]) * (bboxes[:, 3] - bboxes[:, 1])\n",
    "valid_size = areas > 1000\n",
    "bboxes = bboxes[valid_size]\n",
    "bboxes = bboxes[:, :4]\n",
    "\n",
    "\n",
    "\n",
    "init_default_scope('mmpose')\n",
    "pose_results = inference_topdown(pose_estimator, img_path, bboxes)\n",
    "\n",
    "valid_keypoints = []\n",
    "for i, pose_result in enumerate(pose_results):\n",
    "    if pose_result.pred_instances.keypoints.shape[0] > 0:\n",
    "        kpts = pose_result.pred_instances.keypoints[0]\n",
    "        scores = pose_result.pred_instances.keypoint_scores[0]\n",
    "        keypoints_with_conf = np.concatenate([kpts, scores.reshape(-1, 1)], axis=1)\n",
    "        \n",
    "        body_valid = np.sum(scores[:17] > 0.3)\n",
    "        if body_valid >= 5:\n",
    "            valid_keypoints.append(keypoints_with_conf)\n",
    "            print(f\"Person {i+1}: {body_valid}/17 body keypoints, \"\n",
    "                  f\"{np.sum(scores[17:85] > 0.3)}/68 face keypoints\")\n",
    "\n",
    "print(f\"Got valid poses for {len(valid_keypoints)} people\")\n",
    "\n",
    "# 3-part body masks\n",
    "face_combined = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "upper_combined = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "lower_combined = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "expand_ratio = 0.2\n",
    "\n",
    "for person_id, keypoints in enumerate(valid_keypoints):\n",
    "    print(f\"Creating masks for person {person_id + 1}...\")\n",
    "    \n",
    "    # FACE MASK (using face keypoints)\n",
    "    face_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    face_points = []\n",
    "    \n",
    "    # Get face keypoints\n",
    "    for idx in FACE_KEYPOINTS:\n",
    "        if idx < len(keypoints) and keypoints[idx, 2] > 0.2:\n",
    "            face_points.append(keypoints[idx, :2])\n",
    "    \n",
    "    # Add nose point\n",
    "    if keypoints[0, 2] > 0.3:\n",
    "        face_points.append(keypoints[0, :2])\n",
    "    \n",
    "    if len(face_points) > 0:\n",
    "        face_points = np.array(face_points)\n",
    "        \n",
    "        if len(face_points) >= 3:\n",
    "            # Remove outliers\n",
    "            if len(face_points) > 10:\n",
    "                clustering = DBSCAN(eps=50, min_samples=2).fit(face_points)\n",
    "                labels = clustering.labels_\n",
    "                unique_labels, counts = np.unique(labels[labels != -1], return_counts=True)\n",
    "                if len(unique_labels) > 0:\n",
    "                    largest_cluster = unique_labels[np.argmax(counts)]\n",
    "                    face_points = face_points[labels == largest_cluster]\n",
    "            \n",
    "            # Create convex hull\n",
    "            if len(face_points) >= 3:\n",
    "                hull = ConvexHull(face_points)\n",
    "                hull_points = face_points[hull.vertices]\n",
    "                center = np.mean(hull_points, axis=0)\n",
    "                hull_points = center + (hull_points - center) * (1 + expand_ratio)\n",
    "                hull_points = np.clip(hull_points, [0, 0], [img.shape[1]-1, img.shape[0]-1])\n",
    "                cv2.fillPoly(face_mask, [hull_points.astype(np.int32)], 255)\n",
    "            else:\n",
    "                center = np.mean(face_points, axis=0)\n",
    "                radius = max(40, int(np.std(face_points) * (2 + expand_ratio)))\n",
    "                cv2.circle(face_mask, tuple(center.astype(int)), radius, 255, -1)\n",
    "        else:\n",
    "            center = np.mean(face_points, axis=0)\n",
    "            radius = max(35, int(min(img.shape) * 0.06 * (1 + expand_ratio)))\n",
    "            cv2.circle(face_mask, tuple(center.astype(int)), radius, 255, -1)\n",
    "    \n",
    "    # UPPER BODY MASK\n",
    "    upper_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    upper_points = []\n",
    "\n",
    "    for idx in UPPER_BODY_POINTS:\n",
    "        if idx < len(keypoints) and keypoints[idx, 2] > 0.3:\n",
    "            upper_points.append(keypoints[idx, :2])\n",
    "    \n",
    "    if len(upper_points) > 0:\n",
    "        upper_points = np.array(upper_points)\n",
    "        \n",
    "        if len(upper_points) >= 3:\n",
    "            # Remove outliers\n",
    "            if len(upper_points) > 10:\n",
    "                clustering = DBSCAN(eps=50, min_samples=2).fit(upper_points)\n",
    "                labels = clustering.labels_\n",
    "                unique_labels, counts = np.unique(labels[labels != -1], return_counts=True)\n",
    "                if len(unique_labels) > 0:\n",
    "                    largest_cluster = unique_labels[np.argmax(counts)]\n",
    "                    upper_points = upper_points[labels == largest_cluster]\n",
    "            \n",
    "            # Create convex hull\n",
    "            if len(upper_points) >= 3:\n",
    "                hull = ConvexHull(upper_points)\n",
    "                hull_points = upper_points[hull.vertices]\n",
    "                center = np.mean(hull_points, axis=0)\n",
    "                hull_points = center + (hull_points - center) * (1 + expand_ratio)\n",
    "                hull_points = np.clip(hull_points, [0, 0], [img.shape[1]-1, img.shape[0]-1])\n",
    "                cv2.fillPoly(upper_mask, [hull_points.astype(np.int32)], 255)\n",
    "            else:\n",
    "                # Fallback to bounding box\n",
    "                x_min, y_min = np.min(upper_points, axis=0).astype(int)\n",
    "                x_max, y_max = np.max(upper_points, axis=0).astype(int)\n",
    "                \n",
    "                width, height = x_max - x_min, y_max - y_min\n",
    "                expand_w = int(width * expand_ratio)\n",
    "                expand_h = int(height * expand_ratio)\n",
    "                x_min = max(0, x_min - expand_w)\n",
    "                y_min = max(0, y_min - expand_h)\n",
    "                x_max = min(img.shape[1], x_max + expand_w)\n",
    "                y_max = min(img.shape[0], y_max + expand_h)\n",
    "                \n",
    "                cv2.rectangle(upper_mask, (x_min, y_min), (x_max, y_max), 255, -1)\n",
    "    \n",
    "    # LOWER BODY MASK (legs + feet)\n",
    "    lower_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    lower_points = []\n",
    "    \n",
    "    # Get lower body points\n",
    "    for idx in LOWER_BODY_POINTS:\n",
    "        if idx < len(keypoints) and keypoints[idx, 2] > 0.3:\n",
    "            lower_points.append(keypoints[idx, :2])\n",
    "    \n",
    "    if len(lower_points) > 0:\n",
    "        lower_points = np.array(lower_points)\n",
    "        \n",
    "        if len(lower_points) >= 3:\n",
    "            # Remove outliers\n",
    "            if len(lower_points) > 10:\n",
    "                clustering = DBSCAN(eps=50, min_samples=2).fit(lower_points)\n",
    "                labels = clustering.labels_\n",
    "                unique_labels, counts = np.unique(labels[labels != -1], return_counts=True)\n",
    "                if len(unique_labels) > 0:\n",
    "                    largest_cluster = unique_labels[np.argmax(counts)]\n",
    "                    lower_points = lower_points[labels == largest_cluster]\n",
    "            \n",
    "            # Create convex hull\n",
    "            if len(lower_points) >= 3:\n",
    "                hull = ConvexHull(lower_points)\n",
    "                hull_points = lower_points[hull.vertices]\n",
    "                center = np.mean(hull_points, axis=0)\n",
    "                hull_points = center + (hull_points - center) * (1 + expand_ratio)\n",
    "                hull_points = np.clip(hull_points, [0, 0], [img.shape[1]-1, img.shape[0]-1])\n",
    "                cv2.fillPoly(lower_mask, [hull_points.astype(np.int32)], 255)\n",
    "            else:\n",
    "                # Fallback to bounding box\n",
    "                x_min, y_min = np.min(lower_points, axis=0).astype(int)\n",
    "                x_max, y_max = np.max(lower_points, axis=0).astype(int)\n",
    "                \n",
    "                width, height = x_max - x_min, y_max - y_min\n",
    "                expand_w = int(width * expand_ratio)\n",
    "                expand_h = int(height * expand_ratio)\n",
    "                x_min = max(0, x_min - expand_w)\n",
    "                y_min = max(0, y_min - expand_h)\n",
    "                x_max = min(img.shape[1], x_max + expand_w)\n",
    "                y_max = min(img.shape[0], y_max + expand_h)\n",
    "                \n",
    "                cv2.rectangle(lower_mask, (x_min, y_min), (x_max, y_max), 255, -1)\n",
    "    \n",
    "    # Add to combined masks\n",
    "    face_combined[face_mask == 255] = person_id + 1\n",
    "    upper_combined[upper_mask == 255] = person_id + 1\n",
    "    lower_combined[lower_mask == 255] = person_id + 1\n",
    "\n",
    "# Create overlays and save results\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save individual masks\n",
    "cv2.imwrite(os.path.join(output_dir, 'face_mask.png'), face_combined * 60)\n",
    "cv2.imwrite(os.path.join(output_dir, 'upper_body_mask.png'), upper_combined * 60)\n",
    "cv2.imwrite(os.path.join(output_dir, 'lower_body_mask.png'), lower_combined * 60)\n",
    "\n",
    "# Create individual overlays\n",
    "face_overlay = img.copy()\n",
    "upper_overlay = img.copy()\n",
    "lower_overlay = img.copy()\n",
    "\n",
    "# Face overlay\n",
    "unique_persons = np.unique(face_combined)[np.unique(face_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[face_combined == person_id] = FACE_COLOR\n",
    "    face_overlay = cv2.addWeighted(face_overlay, 1, colored_mask.astype(np.uint8), 0.5, 0)\n",
    "\n",
    "# Upper body overlay\n",
    "unique_persons = np.unique(upper_combined)[np.unique(upper_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[upper_combined == person_id] = UPPER_BODY_COLOR\n",
    "    upper_overlay = cv2.addWeighted(upper_overlay, 1, colored_mask.astype(np.uint8), 0.5, 0)\n",
    "\n",
    "# Lower body overlay\n",
    "unique_persons = np.unique(lower_combined)[np.unique(lower_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[lower_combined == person_id] = LOWER_BODY_COLOR\n",
    "    lower_overlay = cv2.addWeighted(lower_overlay, 1, colored_mask.astype(np.uint8), 0.5, 0)\n",
    "\n",
    "\n",
    "cv2.imwrite(os.path.join(output_dir, 'face_overlay.jpg'), cv2.cvtColor(face_overlay, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(os.path.join(output_dir, 'upper_body_overlay.jpg'), cv2.cvtColor(upper_overlay, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(os.path.join(output_dir, 'lower_body_overlay.jpg'), cv2.cvtColor(lower_overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Create combined overlay\n",
    "combined_overlay = img.copy()\n",
    "\n",
    "# face\n",
    "unique_persons = np.unique(face_combined)[np.unique(face_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[face_combined == person_id] = FACE_COLOR\n",
    "    combined_overlay = cv2.addWeighted(combined_overlay, 1, colored_mask.astype(np.uint8), 0.4, 0)\n",
    "\n",
    "# upper body\n",
    "unique_persons = np.unique(upper_combined)[np.unique(upper_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[upper_combined == person_id] = UPPER_BODY_COLOR\n",
    "    combined_overlay = cv2.addWeighted(combined_overlay, 1, colored_mask.astype(np.uint8), 0.4, 0)\n",
    "\n",
    "# lower body\n",
    "unique_persons = np.unique(lower_combined)[np.unique(lower_combined) > 0]\n",
    "for person_id in unique_persons:\n",
    "    colored_mask = np.zeros_like(img)\n",
    "    colored_mask[lower_combined == person_id] = LOWER_BODY_COLOR\n",
    "    combined_overlay = cv2.addWeighted(combined_overlay, 1, colored_mask.astype(np.uint8), 0.4, 0)\n",
    "\n",
    "\n",
    "legend_height = 60\n",
    "legend = np.ones((legend_height, img.shape[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "legend_items = [\n",
    "    (\"Face\", FACE_COLOR),\n",
    "    (\"Upper Body (no face/neck)\", UPPER_BODY_COLOR),\n",
    "    (\"Lower Body (Legs)\", LOWER_BODY_COLOR)\n",
    "]\n",
    "\n",
    "x_offset = 10\n",
    "for label, color in legend_items:\n",
    "    cv2.rectangle(legend, (x_offset, 15), (x_offset + 25, 35), color, -1)\n",
    "    cv2.rectangle(legend, (x_offset, 15), (x_offset + 25, 35), (0, 0, 0), 1)\n",
    "    cv2.putText(legend, label, (x_offset + 35, 30), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    x_offset += 250\n",
    "\n",
    "cv2.putText(legend, \"3-Part Body Segmentation (Face, Upper Body, Legs)\", (10, 50), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)\n",
    "\n",
    "final_result = np.vstack([combined_overlay, legend])\n",
    "cv2.imwrite(os.path.join(output_dir, 'combined_3part_overlay.jpg'), cv2.cvtColor(final_result, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "pose_vis = img.copy()\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(valid_keypoints)))[:, :3] * 255\n",
    "\n",
    "for person_id, keypoints in enumerate(valid_keypoints):\n",
    "    color = colors[person_id].astype(int).tolist()\n",
    "    \n",
    "\n",
    "    for i in range(17):\n",
    "        if i < len(keypoints) and keypoints[i, 2] > 0.3:\n",
    "            cv2.circle(pose_vis, tuple(keypoints[i, :2].astype(int)), 4, color, -1)\n",
    "    \n",
    "    for i in range(17, min(85, len(keypoints))):\n",
    "        if keypoints[i, 2] > 0.2:\n",
    "            cv2.circle(pose_vis, tuple(keypoints[i, :2].astype(int)), 1, color, -1)\n",
    "    \n",
    "    body_connections = [\n",
    "        (0, 1), (0, 2), (1, 3), (2, 4),\n",
    "        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),\n",
    "        (5, 11), (6, 12), (11, 12),\n",
    "        (11, 13), (13, 15), (12, 14), (14, 16)\n",
    "    ]\n",
    "    \n",
    "    for pt1_idx, pt2_idx in body_connections:\n",
    "        if (pt1_idx < len(keypoints) and pt2_idx < len(keypoints) and \n",
    "            keypoints[pt1_idx, 2] > 0.3 and keypoints[pt2_idx, 2] > 0.3):\n",
    "            pt1 = tuple(keypoints[pt1_idx, :2].astype(int))\n",
    "            pt2 = tuple(keypoints[pt2_idx, :2].astype(int))\n",
    "            cv2.line(pose_vis, pt1, pt2, color, 2)\n",
    "\n",
    "cv2.imwrite(os.path.join(output_dir, 'pose_visualization.jpg'), cv2.cvtColor(pose_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "for i, keypoints in enumerate(valid_keypoints):\n",
    "    body_kpts = np.sum(keypoints[:17, 2] > 0.3)\n",
    "    face_kpts = np.sum(keypoints[17:85, 2] > 0.2) if len(keypoints) > 85 else 0\n",
    "    upper_kpts = np.sum([keypoints[idx, 2] > 0.3 for idx in UPPER_BODY_POINTS if idx < len(keypoints)])\n",
    "    print(f\"  Person {i+1}: {body_kpts}/17 body, {face_kpts}/68 face, {upper_kpts}/8 upper body keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8090277,
     "sourceId": 12796183,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8215790,
     "sourceId": 12984865,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
